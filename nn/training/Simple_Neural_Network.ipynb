{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "02y9obGZ0wad"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def create_tensor(file,device):\n",
        "  load_in = []\n",
        "  load_out = []\n",
        "\n",
        "  for line in file:\n",
        "    load_seq=line[:-1].split(\",\")\n",
        "    load_in.append(load_seq[:5])\n",
        "    load_out.append(load_seq[5])\n",
        "\n",
        "  load_in = np.array(load_in).astype(int)\n",
        "  load_out = np.array(load_out).astype(int)\n",
        "\n",
        "  input_tensor = torch.tensor(load_in,dtype=torch.float32).to(device)\n",
        "  output_tensor = torch.tensor(load_out,dtype=torch.float32).to(device)\n",
        "  return (input_tensor,output_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,output_size):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
        "        self.fc1 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x,_ = self.lstm(x)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "c94ZgT0MZ6iK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, input_tensor,output_tensor, loss_fn, optimizer, num_epochs):\n",
        "  index = 0\n",
        "  batch = []\n",
        "  for i in range (18):\n",
        "    batch.append([input_tensor[index:index+34],output_tensor[index:index+34]])\n",
        "    index+=34\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    for (X,y) in batch:\n",
        "      X,y = X.to(device),y.to(device)\n",
        "      output = model(X)\n",
        "      loss = loss_fn(output.squeeze(), y)\n",
        "\n",
        "      train_loss +=loss.item()\n",
        "\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "    train_loss = train_loss / len(input_tensor)\n",
        "  return train_loss"
      ],
      "metadata": {
        "id": "iaaLU-8emnv0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For Bin Load"
      ],
      "metadata": {
        "id": "lp7jyBiXNlVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNet(input_size=5,hidden_size=32,output_size=1).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "load_file = open(\"load_values_612.txt\",\"r\")\n",
        "input_tensor,output_tensor = create_tensor(load_file,device)\n",
        "\n",
        "model.train()\n",
        "num_epochs = 1500\n",
        "results = train(model,input_tensor,output_tensor,loss_fn,optimizer,num_epochs)\n",
        "\n",
        "print(\"Loss\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "jt_rfwSCZ-Tl",
        "outputId": "a0528f91-a92b-47eb-c0f1-382b8b591235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1500], Loss: 1.5486\n",
            "Epoch [200/1500], Loss: 1.5495\n",
            "Epoch [300/1500], Loss: 1.1728\n",
            "Epoch [400/1500], Loss: 1.1851\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-210-79a8e3c30192>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-209-dfef8192cedc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, input_tensor, output_tensor, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor_test = torch.tensor([[15,15,23,31,37]], dtype=torch.float32)\n",
        "predicted_output = model(input_tensor_test.to(device)).item()\n",
        "print(\"Predicted next number:\", predicted_output) #43\n",
        "\n",
        "input_tensor_test = torch.tensor([[30,35,43,49,57]], dtype=torch.float32)\n",
        "predicted_output = model(input_tensor_test.to(device)).item() #65\n",
        "print(\"Predicted next number:\", predicted_output)\n",
        "\n",
        "input_tensor_test = torch.tensor([[44,49,55,63,71]], dtype=torch.float32)\n",
        "predicted_output = model(input_tensor_test.to(device)).item()\n",
        "print(\"Predicted next number:\", predicted_output) #76\n"
      ],
      "metadata": {
        "id": "3_n7wikqVvys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH  = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,\n",
        "                 exist_ok=True)\n",
        "\n",
        "MODEL_NAME = \"bin_load_nn.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
        "\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "BspguJvQWjyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For temperature"
      ],
      "metadata": {
        "id": "q1EkteSxWmvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_model = SimpleNet(input_size=5,hidden_size=32,output_size=1).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(temp_model.parameters(), lr=0.001)\n",
        "\n",
        "load_file = open(\"temp_values_612.txt\",\"r\")\n",
        "input_tensor,output_tensor = create_tensor(load_file,device)\n",
        "\n",
        "temp_model.train()\n",
        "num_epochs = 1500\n",
        "results = train(temp_model,input_tensor,output_tensor,loss_fn,optimizer,num_epochs)\n",
        "\n",
        "print(\"Loss\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-8mxJL1NkMK",
        "outputId": "94e7f1aa-1fef-4e85-e825-1aa0c6d318c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1500], Loss: 4.1727\n",
            "Epoch [200/1500], Loss: 2.8673\n",
            "Epoch [300/1500], Loss: 2.0382\n",
            "Epoch [400/1500], Loss: 2.0067\n",
            "Epoch [500/1500], Loss: 2.0270\n",
            "Epoch [600/1500], Loss: 2.1252\n",
            "Epoch [700/1500], Loss: 2.1288\n",
            "Epoch [800/1500], Loss: 2.1127\n",
            "Epoch [900/1500], Loss: 2.0883\n",
            "Epoch [1000/1500], Loss: 2.0302\n",
            "Epoch [1100/1500], Loss: 1.9889\n",
            "Epoch [1200/1500], Loss: 1.9362\n",
            "Epoch [1300/1500], Loss: 1.8735\n",
            "Epoch [1400/1500], Loss: 1.8142\n",
            "Epoch [1500/1500], Loss: 1.7788\n",
            "Loss 0.04139346643990161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor_test = torch.tensor([[39,41,40,39,39]], dtype=torch.float32)\n",
        "predicted_output = temp_model(input_tensor_test.to(device)).item()\n",
        "print(\"Predicted next number:\", predicted_output) #38\n",
        "\n",
        "input_tensor_test = torch.tensor([[37,38,37,38,38]], dtype=torch.float32)\n",
        "predicted_output = temp_model(input_tensor_test.to(device)).item() #39\n",
        "print(\"Predicted next number:\", predicted_output)\n",
        "\n",
        "input_tensor_test = torch.tensor([[37,36,36,38,38]], dtype=torch.float32)\n",
        "predicted_output = temp_model(input_tensor_test.to(device)).item()\n",
        "print(\"Predicted next number:\", predicted_output) #37"
      ],
      "metadata": {
        "id": "iDPSyKJwWekL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4965c6-55fa-466a-b1ec-f5206327e9d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next number: 39.91593551635742\n",
            "Predicted next number: 37.736412048339844\n",
            "Predicted next number: 36.277442932128906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH  = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,\n",
        "                 exist_ok=True)\n",
        "\n",
        "MODEL_NAME = \"bin_temp_nn.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
        "\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=temp_model.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtF-_3e9WS9w",
        "outputId": "c196f4cf-796d-4e33-b57d-3b5e64f349b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/bin_temp_nn.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For humidity"
      ],
      "metadata": {
        "id": "KHfh8jhjWuzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hum_model = SimpleNet(input_size=5,hidden_size=32,output_size=1).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(hum_model.parameters(), lr=0.0001)\n",
        "\n",
        "load_file = open(\"hum_values_612.txt\",\"r\")\n",
        "input_tensor,output_tensor = create_tensor(load_file,device)\n",
        "\n",
        "hum_model.train()\n",
        "num_epochs = 1500\n",
        "results = train(hum_model,input_tensor,output_tensor,loss_fn,optimizer,num_epochs)\n",
        "\n",
        "print(\"Loss\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHCdJD8mWe-x",
        "outputId": "e404b341-ea37-4759-a9d9-ffcf5dee8147"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1500], Loss: 68.7704\n",
            "Epoch [200/1500], Loss: 19.0892\n",
            "Epoch [300/1500], Loss: 6.1682\n",
            "Epoch [400/1500], Loss: 4.5094\n",
            "Epoch [500/1500], Loss: 4.4172\n",
            "Epoch [600/1500], Loss: 4.1892\n",
            "Epoch [700/1500], Loss: 3.7822\n",
            "Epoch [800/1500], Loss: 3.4363\n",
            "Epoch [900/1500], Loss: 3.1290\n",
            "Epoch [1000/1500], Loss: 2.6246\n",
            "Epoch [1100/1500], Loss: 2.1298\n",
            "Epoch [1200/1500], Loss: 1.8623\n",
            "Epoch [1300/1500], Loss: 1.7746\n",
            "Epoch [1400/1500], Loss: 1.5624\n",
            "Epoch [1500/1500], Loss: 1.4887\n",
            "Loss 0.057399201821657565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor_test = torch.tensor([[30,33,36,39,37]], dtype=torch.float32)\n",
        "predicted_output = hum_model(input_tensor_test.to(device)).item()\n",
        "print(\"Predicted next number:\", predicted_output) #41\n",
        "\n",
        "input_tensor_test = torch.tensor([[33,33,35,38,39]], dtype=torch.float32)\n",
        "predicted_output = hum_model(input_tensor_test.to(device)).item() #40\n",
        "print(\"Predicted next number:\", predicted_output)\n",
        "\n",
        "input_tensor_test = torch.tensor([[40,41,44,30,31]], dtype=torch.float32)\n",
        "predicted_output = hum_model(input_tensor_test.to(device)).item()\n",
        "print(\"Predicted next number:\", predicted_output) #32\n"
      ],
      "metadata": {
        "id": "f2LayjR4rdnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d764a8-5fe9-4858-e514-55412dd89c51"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next number: 35.48539733886719\n",
            "Predicted next number: 39.773681640625\n",
            "Predicted next number: 31.625503540039062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH  = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,\n",
        "                 exist_ok=True)\n",
        "\n",
        "MODEL_NAME = \"bin_hum_nn.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
        "\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=hum_model.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "oJ3ida1S9vZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fed0f43-bc80-4be8-89d6-39a42141ddab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/bin_hum_nn.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = SimpleNet(input_size=5,hidden_size=32,output_size=1)\n",
        "model_2.load_state_dict(torch.load(f=\"./models/bin_load_nn.pth\"))"
      ],
      "metadata": {
        "id": "mn6fYqYWGXNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor_test = torch.tensor([[15,15,23,31,37]], dtype=torch.float32)\n",
        "predicted_output = model_2(input_tensor_test).item()\n",
        "print(\"Predicted next number:\", predicted_output) #43"
      ],
      "metadata": {
        "id": "4PTDuESJGaXM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}